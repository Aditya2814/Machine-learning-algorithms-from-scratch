{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e12059",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA:\n",
    "  def __init__(self, n_dimensions=None):\n",
    "    self.n_dimensions_ = n_dimensions\n",
    "    self.linear_discriminants_ = []\n",
    "    self.explained_variances_ = None\n",
    "    self.classes = None\n",
    "\n",
    "  def scatter_matrix_within_class(self, X, Y):\n",
    "    classes = np.unique(Y)\n",
    "    \n",
    "    Sw = 0            # Sw = Within-class scatter matrix.\n",
    "    for i in classes:\n",
    "      X_cat = X[Y == i]\n",
    "      mean = np.mean(X_cat, axis=0)\n",
    "      Sw += np.dot((X_cat-mean).T, (X_cat-mean))\n",
    "\n",
    "    return Sw\n",
    "\n",
    "  def scatter_matrix_between_class(self, X, Y):\n",
    "    self.classes = np.unique(Y)\n",
    "\n",
    "    mean_overall = np.mean(X, axis=0) # overall mean\n",
    "    mean_overall = mean_overall.reshape(1, -1)\n",
    "\n",
    "    Sb = 0             # Sw = Between-class scatter matrix.\n",
    "    for i in self.classes:\n",
    "      X_cat = X[Y == i]\n",
    "      number_of_instances = X_cat.shape[0]\n",
    "      mean = np.mean(X_cat, axis=0)\n",
    "      mean = mean.reshape(1, -1)\n",
    "      Sb += number_of_instances*(np.dot((mean - mean_overall).T, (mean - mean_overall)))\n",
    "\n",
    "    return Sb\n",
    "\n",
    "  def fit(self, X, Y, variance_threshold=None):\n",
    "    Sw = self.scatter_matrix_within_class(X, Y) # within class scatter matrix\n",
    "    Sb = self.scatter_matrix_between_class(X, Y) # between class scatter matrix\n",
    "\n",
    "    mat = np.dot(np.linalg.inv(Sw), Sb) \n",
    "    \n",
    "    eigenvalues, eigenvectors = eig(mat) # eigen values and vectors\n",
    "    eigenvectors = eigenvectors.T \n",
    "\n",
    "    index = np.argsort(eigenvalues)[::-1] # sorting in descending order the eigen vectors according to the eigen values.\n",
    "    eigenvalues = eigenvalues[index]\n",
    "    eigenvectors = eigenvectors[index]\n",
    "\n",
    "    self.explained_variances_ = np.cumsum(eigenvalues) / np.sum(eigenvalues) # \n",
    "\n",
    "    if self.n_dimensions_ is None: # if the number of dimensions are not specified, it would take that number of dimensions which has variance greater than specified variance threshold.\n",
    "      self.n_dimensions_ = np.argmax(np.real(self.explained_variances_) >= variance_threshold) + 1\n",
    "\n",
    "    self.linear_discriminants_ = np.real(eigenvectors[: self.n_dimensions_]) # complex part is anyway zero so taking only real part.\n",
    "\n",
    "  def transform(self, X):\n",
    "    return np.dot(X, (self.linear_discriminants_).T) # transformation of the points.\n",
    "\n",
    "  def predict(self, X):\n",
    "    X_lda = self.transform(X) # transform the data points to the LDA subspace\n",
    "\n",
    "    y_pred = np.zeros(X.shape[0], dtype=self.classes.dtype) # initialize an array to store the predicted classes\n",
    "\n",
    "    for i, x_lda in enumerate(X_lda):\n",
    "      distances = [np.linalg.norm(x_lda - np.mean(self.transform(X[Y == c]), axis=0)) for c in self.classes] # compute the distances between the LDA-transformed data point and the class means\n",
    "      y_pred[i] = self.classes[np.argmin(distances)] # assign the class of the nearest mean to the data point\n",
    "\n",
    "    return y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ec94b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(a):\n",
    "  # list of all the classes in the feature\n",
    "  classes = np.unique(a)\n",
    "  entropy = 0                             \n",
    "  for i in classes:\n",
    "    # counting the number of instances of a class\n",
    "    # count_of_class = a.value_counts()[i]\n",
    "    count_of_class = np.count_nonzero(a == i)\n",
    "    probability = count_of_class/len(a)   \n",
    "    # formula of entropy      \n",
    "    entropy += (-1)*probability*math.log(probability,2)\n",
    "  return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee536a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class decisiontreeclassifier:\n",
    "\n",
    "  def __init__(self, max_depth=5): # setting max_depth = 5 as default\n",
    "    self.max_depth = max_depth\n",
    "    self.x_train = None\n",
    "    self.y_train = None\n",
    "    self.tree = None\n",
    "\n",
    "  def best_split_feature(self, x_train, y_train): #function to find attribute that leads to the best split using information gain.\n",
    "    if x_train.shape[0] == 0 or x_train.shape[1] == 0: # to handle the cases when x_train has 0 columns or 0 rows.\n",
    "      return None\n",
    "    entropy_df = entropy(y_train) #entropy of whole dataset\n",
    "    no_of_features = x_train.shape[1]\n",
    "    info_gain_of_features = []\n",
    "    for i in range(no_of_features):\n",
    "      categories = np.unique(x_train[:, i])\n",
    "      info_gain = entropy_df\n",
    "      for j in categories:\n",
    "        entropy_j = entropy(y_train[x_train[:, i] == j])\n",
    "        info_gain += (-1)*entropy_j*len(x_train[x_train[:, i] == j]) / len(y_train)\n",
    "      info_gain_of_features.append(info_gain)\n",
    "          \n",
    "    return np.argmax(info_gain_of_features)\n",
    "\n",
    "  def mode(self, arr): # function to calculate mode of an array\n",
    "    if(len(arr) == 0): \n",
    "      return None\n",
    "    uniq = np.unique(arr)\n",
    "    Dict = {}\n",
    "    for i in uniq:\n",
    "      Dict[i] = np.count_nonzero(arr == i)\n",
    "    return max(Dict, key=lambda k: Dict[k])\n",
    "\n",
    "  def make_split(self, x_train, y_train, depth):\n",
    "    if depth >= self.max_depth:\n",
    "      return {'Class': self.mode(y_train)}\n",
    "\n",
    "    if len(np.unique(y_train)) == 1:\n",
    "      return {'Class': self.mode(y_train)}\n",
    "\n",
    "    BestSplitFeature = self.best_split_feature(x_train, y_train)\n",
    "    categories = np.unique(x_train[:, BestSplitFeature])\n",
    "    node = {'split_feature': BestSplitFeature, 'children': []}\n",
    "    for i in range(len(categories)):\n",
    "      x_train_splitted = x_train[x_train[:, BestSplitFeature] == i]\n",
    "      y_train_splitted = y_train[x_train[:, BestSplitFeature] == i]\n",
    "      x_train_splitted = np.delete(x_train_splitted, BestSplitFeature, axis=1)\n",
    "      child = self.make_split(x_train_splitted, y_train_splitted, depth+1)\n",
    "      node['children'].append((i, child))\n",
    "    \n",
    "    return node\n",
    "\n",
    "  def train(self, x_train, y_train):\n",
    "    self.x_train = x_train\n",
    "    self.y_train = y_train\n",
    "    self.tree = self.make_split(x_train, y_train, 0)\n",
    "\n",
    "  def test(self, x_test):\n",
    "    predictions = []\n",
    "    for x in x_test:\n",
    "      current_node = self.tree\n",
    "      while current_node.get('children') is not None:\n",
    "        split_feature = current_node.get('split_feature')\n",
    "        category = x[split_feature]\n",
    "        for child in current_node.get('children'):\n",
    "            if child[0] == category:\n",
    "              current_node = child[1]\n",
    "              break\n",
    "      predictions.append(current_node['Class'])\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c386a4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert continuous features to categorical features optimally.\n",
    "\n",
    "def cont_to_cat(feature):\n",
    "  x = np.array(feature)\n",
    "  y = np.array(df['species'])\n",
    "\n",
    "  sorted_indices = np.argsort(x)\n",
    "\n",
    "  x = x[sorted_indices]\n",
    "  y = y[sorted_indices]\n",
    "\n",
    "  x = x.reshape(-1,1)\n",
    "  y = y.reshape(-1,1)\n",
    "\n",
    "  z = np.hstack((x,y))\n",
    "  \n",
    "  length_z = len(z)\n",
    "  info_gain_i = []\n",
    "  for i in range(length_z):\n",
    "\n",
    "    z[:i+1, 0] = 0\n",
    "    z[i+1:, 0] = 1\n",
    "\n",
    "    z0 = z[z[:, 0] == 0]\n",
    "    z1 = z[z[:, 0] == 1]\n",
    "\n",
    "    entropy_z0 = entropy(z0[:, 1])\n",
    "    entropy_z1 = entropy(z1[:, 1])\n",
    "    entropy_z = entropy(z[:, 1])\n",
    "\n",
    "    length_z0 = len(z0)\n",
    "    length_z1 = len(z1)\n",
    "\n",
    "    info_gain = entropy_z - (length_z0*entropy_z0 / length_z) - (length_z1*entropy_z1 / length_z)\n",
    "\n",
    "    info_gain_i.append(info_gain)\n",
    "\n",
    "  info_gain_i = np.array(info_gain_i)\n",
    "\n",
    "  max_index = np.argmax(info_gain_i)\n",
    "\n",
    "  z[:max_index+1, 0] = 0\n",
    "  z[max_index+1:, 0] = 1\n",
    "\n",
    "  x = z[:, 0]\n",
    "\n",
    "  x_original = x[np.argsort(sorted_indices)]\n",
    "\n",
    "  return x_original"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
